---
title: "DSA2101 Group Project: Analysis of Taylor Swift Spotify Data"
output: github_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
library(tidytuesdayR)
library(tidyverse)
library(readr)
library(knitr)
library(ggthemes)
```

## Group members
```{r, echo = FALSE}
students <- data.frame(
  Group_Members = c("Chua Yong Sheng Joel", "Lim Zeen Kiat", "Robin Ghosh", "Timothy Teo Shao Jun"),
  Matriculation_Number = c("A0282307H", "A0273151M", "A0271671A", "A0272851B")
)

kable(students, col.names = c("Group Members", "Matriculation Number"))
```

## Loading Data
```{r}
# Load the Taylor Swift datasets
tuesdata <- tidytuesdayR::tt_load(2023, week = 42)

taylor_album_songs <- tuesdata$taylor_album_songs
taylor_all_songs <- tuesdata$taylor_all_songs
taylor_albums <- tuesdata$taylor_albums

# Save each dataset to new CSV files
# write.csv(taylor_album_songs, "taylor_album_songs.csv", row.names = FALSE)
# write.csv(taylor_all_songs, "taylor_all_songs.csv", row.names = FALSE)
# write.csv(taylor_albums, "taylor_albums.csv", row.names = FALSE)
```
=======

## 1. Introduction

Taylor Swift's music has had a significant impact on the global pop and country music scene. 
In this project, we used the Taylor Swift Spotify data sourced from the TidyTuesday repository (Harmon, 2023) to analyse the musical and lyrical features of her music. 
This dataset includes detailed audio attributes of her songs which we aim to use. 
By exploring the given data, we aim to discover the patterns that have emerged throughout Taylor Swift’s career and gain insights into how her music has evolved.


### Brief description of the Dataset
`taylor_album_songs` ~ Song features and *metadata* for only songs released in albums.

`taylor_all_songs` ~ Song features and *metadata* for all songs released by Artist

`taylor_albums` ~ *Metadata* for each album, together with Metacritic and User Scores (Used as receptivity metrics).

* **Metadata** refers to technical aspects of the release like track name, track number and release dates.
* Download dataset from: https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-10-17/readme.md


For our project, we aim to answer the following question:

```bash
"How have changes in musical and lyrical features in Taylor Swift's songs resonated with her audience?" 
```
This analysis will allow us to identify trends in musical characteristics and examine how stylistic changes in her songs which have affected the receptivity of her music to her audience. 
We also hope to understand her audience better by knowing their music preferences through this study. Hence, we can perhaps understand what makes Taylor Swift so popular.


## 2. Data Cleaning & Summary

### Summary of relevant statistics
The following table contains a brief description of the variables we have chosen to use for our project (Harmon, 2023):
These features will enable us to compare the songs' descriptive features through a quantitative lense, allowing us to make judgements backed by figures. 
```{r, echo = FALSE}
track_attributes <- data.frame(
  Variable = c(
    "album_name", "album_release", "track_name", "danceability", "energy", 
    "loudness", "mode", "speechiness", "acousticness", "instrumentalness", 
    "liveness", "valence", "tempo", "explicit", "Metacritic Score", "User Score"
  ),
  Class = c(
    "character", "double", "character", "double", "double", "double", "integer",
    "double", "double", "double", "double", "double", "double", "logical", "double", "double"
  ),
  Description = c(
    "Name of the album the track belongs to.",
    "Release date of the album.",
    "Name of the individual track.",
    "Measures how suitable a track is for dancing.",
    "Measures the intensity and activity of a track, with higher values indicating more energetic sounds.",
    "The overall volume of the track, measured in decibels (dB).",
    "This is a categorical variable. It indicates the modality of the track: 1 for major, 0 for minor.",
    "Measures the presence of spoken words in a track, with higher values indicating more speech-like content.",
    "Represents the likelihood that the track is acoustic, with higher values indicating more acoustic qualities.",
    "Predicts whether a track is instrumental, with higher values suggesting a lack of vocals.",
    "Measures the presence of an audience in the recording, with higher values indicating a stronger likelihood that the track is live",
    "Describes the musical positiveness conveyed, with higher values indicating more cheerful and happy tones.",
    "The speed of the track, measured in beats per minute (BPM).",
    "Indicates whether the track contains explicit content: 1 for explicit, 0 otherwise.",
    "Average score of the album obtained from critics at Metacritic.com",
    "Average score of the album obtained from average users at Meatcritic.com"
  )
)
kable(track_attributes, col.names = c("Variable", "Class", "Description"), align = "l")
```

### Data cleaning
We'll start off by filtering for the features listed above. We do not need the "EP" flag as well
because we are interested in **all** the songs in her albums which are present in `taylor_albums`. 
```{r}
taylor_album_songs <- taylor_album_songs %>%
  select(album_name, album_release, track_number, track_name, danceability, energy, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, explicit)

taylor_all_songs <- taylor_all_songs %>%
  select(album_name, album_release, track_number, track_name, danceability, energy, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, explicit)

taylor_albums <- taylor_albums %>%
    select(!ep)
```

Then, we group the data by their **respective albums** for aggregating album data:
```{r}
taylor_album_songs <- taylor_album_songs %>%
  group_by(album_name)

taylor_all_songs <- taylor_all_songs %>%
  group_by(album_name)

taylor_albums <- taylor_albums %>%
  group_by(album_name)
```

We will check and remove NA values in the data, which are not needed for our visualisations:
```{r}
taylor_album_songs_na_count <- sapply(taylor_album_songs, function(x) sum(is.na(x)))
print(taylor_album_songs_na_count)

taylor_all_songs_na_count <- sapply(taylor_all_songs, function(x) sum(is.na(x)))
print(taylor_all_songs_na_count)

taylor_albums_na_count <- sapply(taylor_albums, function(x) sum(is.na(x)))
print(taylor_albums_na_count)

taylor_album_songs <- taylor_album_songs %>%
    na.omit()

taylor_all_songs <- taylor_all_songs %>%
    na.omit()

taylor_albums <- taylor_albums %>%
    na.omit()
```

Next we will check if data presented by `taylor_album_songs` and `taylor_all_songs` are the same, in case we are missing crucial differences.
```{r}
names(taylor_album_songs) == names(taylor_all_songs)
checking_conflicts_left <- taylor_album_songs %>% anti_join(taylor_all_songs, by = names(taylor_all_songs))
glimpse(checking_conflicts_left)
checking_conflicts_right <- taylor_all_songs %>% anti_join(taylor_album_songs, by = names(taylor_album_songs))
glimpse(checking_conflicts_right)
checking_conflicts_right$album_name %>% unique
```

All the column names match for both tables. There were no non-matching songs in `taylor_album_songs` to `taylor_all_songs`. However, there were 3 albums: "Fearless", "Red" and "The Taylor Swift Holiday Collection", which were found in `taylor_all_songs` but not `taylor_album_songs`.
This means that we should use data from the overarching dataset to give us the widest coverage, hence use `taylor_all_songs`. 
Next, since we will compare receptivity statistics by album, we need to check which albums are present in `taylor_all_songs` and `taylor_albums`.

```{r}
names1 <- taylor_albums %>% select(album_name) %>% unique() %>% arrange(album_name)
names2 <- taylor_all_songs %>% select(album_name) %>% unique() %>% arrange(album_name)

comp_table <- full_join(names1, names2, by = c("album_name"))

combined_table <- rep("No", length(comp_table$album_name))
combined_table <- cbind(combined_table, combined_table)

for (i in 1:length(comp_table$album_name)){
  if (comp_table$album_name[i] %in% names1$album_name) {
    combined_table[i, 1] <- "Yes"
  }
  if (comp_table$album_name[i] %in% names2$album_name) {
    combined_table[i, 2] <- "Yes"
  }
}

combined_table <- cbind(comp_table$album_name, combined_table)
knitr::kable(combined_table, col.names = c("All Albums", "Taylor Albums", "Taylor All Songs"), caption = "Comparison of album names between the tables")
```

Checking the table generated, "The Taylor Swift Holiday Collection" does not appear in `taylor_albums`, thus it will not be considered for receptivity comparison as there is no receptivity data. We will remove that album from `taylor_all_songs`.
```{r removing-The-Taylor-Swift-Holiday-Collection}
taylor_all_songs <- taylor_all_songs %>% filter(album_name != "The Taylor Swift Holiday Collection")
```

To ensure that the visualisation representations are balanced, we will check the range of the various song features in `taylor_all_songs` to see if there is a need to scale the features:
```{r}
# Checking range of values (for all the songs) of numerical variables in taylor_all_songs
ranges_taylor_all_songs <- taylor_all_songs %>%
  ungroup() %>%
  select(danceability:tempo) %>%
  summarise(across(danceability:tempo, ~paste(min(.), "to", max(.))))
glimpse(ranges_taylor_all_songs)

```

From the data dictionary in TidyTuesday, all the features scores except loudness and tempo range from 0 to 1, hence we do not need the scale them.
We are left with loudness and tempo for normalisation. Loudness is measured in decibels, which has a logarithmic scale. To enable a clearer visual representation, we will convert the values of loudness to a linear scale between 0 and 1. 1 represents loudest while 0 represents softest.
We will use min_max scaling for tempo, to fit it into the 0 to 1 scaling in line with the other features (not for direct comparison to the features as range is fixed by us).
```{r}
# Scaling loudness for taylor_all_songs
taylor_all_songs <- taylor_all_songs %>%
  ungroup() %>%
  mutate(loudness = 10^(loudness / 10), tempo = (tempo - min(tempo)) / (max(tempo) - min(tempo))) #%>%
glimpse(taylor_all_songs)
```


### Data engineering
Let's look at the cleaned dataframes for each `taylor_all_songs` and `taylor_albums`.
```{r using-cleaned-datasets}
head(taylor_all_songs, 10)
head(taylor_albums, 10)
```

To compare musical attributes across albums, we will aggregate statistics for each of the musical attributes in each album by taking their mean. Then, we will combine `taylor_all_songs` and `taylor_albums` to tie the receptivity metrics with each common album.
```{r aggregating-statistics}
taylor_album_summary <- taylor_all_songs %>% group_by(album_name) %>% summarize(
  mean_loudness = mean(loudness),
  mean_danceability = mean(danceability),
  mean_liveness = mean(liveness),
  mean_energy = mean(energy),
  mean_mode = round(mean(mode)),
  mean_speechiness = mean(speechiness),
  mean_acousticness = mean(acousticness),
  mean_instrumentalness = mean(instrumentalness),
  mean_valence = mean(valence),
  mean_tempo = mean(tempo)) %>%
  inner_join(taylor_albums, by = c("album_name")) %>%
  relocate(album_release, .after = album_name)
```

Metacritic scores and user scores are representative of the receptivity of the albums because they are the "weighted average" of the albums' individual ratings
from critics and the public respectively (Metacritic, 2023).

While the Metacritic score ranges from 0 to 100 (Metacritic, 2023), the user score has a different range of 0 to 10 which we noticed when exploring the "user reviews" section (Metacritic, n.d.).
We will aggregate these into one statistic, "Receptivity", weighted by their respective ranges. 

Hence we use the following formula: Receptivity = (metacritic_score+(user_score*10))/2

```{r creating-Receptivity}
taylor_album_summary <- taylor_album_summary %>% mutate(Receptivity = (metacritic_score + user_score * 10) / 2)
```


## 3. Visualisations and Discussions
### a. What are the most significant features?

#### Methodology
We have chosen to use an overlayed boxplot and violin plot to represent the values of the song features, less tempo. This will allow us to examine the spread and distribution of values for each feature together with information about the interquartile range and median.
The violin plot additionally shows potential polarisation in the data as it is a density plot of the values. Additionaly, a colourblind friendly scheme was used to differentiate each feature.

#### Plot
```{r boxplot}
# Defining labels for usage
x_labels <- c("Acousticness", "Danceability", "Energy", "Instrumentalness", "Liveness", "Loudness", "Speechiness", "Valence")

# Convertion to long format for plotting
taylor_long <- taylor_all_songs %>% select(-mode) %>% pivot_longer(danceability:tempo, values_to = "values", names_to = "labels") %>%
  mutate(labels <- as.factor(labels))

# Plot
ggplot(taylor_long %>% filter(labels != "tempo"), aes(y = labels, x = values, fill = labels)) +
  geom_violin(show.legend = FALSE, alpha = 0.8, bw = 0.1, color = FALSE) +
  geom_boxplot(show.legend = FALSE, alpha = 0.6, fill = "lightblue", outlier.fill = "lightblue", width = 0.4) +
  theme_economist() +
  labs(y = "", x = "Magnitude (From 0 to 1)", title = "Boxplot of musical features for Swift's songs") +
  scale_y_discrete(labels = x_labels) +
  scale_fill_colorblind() +
  theme(
    axis.text.x = element_text(size = 6), 
    axis.text.y = element_text(size = 8),
    axis.title.x = element_text(vjust = -1, size = 10),
    plot.title = element_text(size = 16),
    aspect.ratio = 0.4,
    plot.background = element_rect(fill = "#fae7d7")
  )
```

#### Discussion

From this visualisation, we can pinpoint those features with a higher variance, as they likely contribute more significantly to changes in her musical style, hence her receptivity.
By focusing on features that show the widest range (i.e. most diverse expressions) across her songs, we can identify the more significant attributes that make her music unique. 
We will use these features in the next visualisation to examine their possible relationship with Swift's receptivity.  

It appears that `valence`, `acousticness`, `energy` and `danceability` have the most variance - the tails for each feature spans the widest across the graph. This indicates vast differences between these features within Swift's songs. Such differences could indicate large dynamic shifts in the style of music produced, which will likely be received differently by the audience. 
The rest of the musical features seem to be concentrated closer to zero, indicating that most of the features are weakly present and consistent throughout the songs. Additionally, since `loudness` values are mostly closer to 0, it indicates that Swift's songs are consistently moderately loud. Overall we gather that most of her songs are vocally driven (low `instrumentalness`), not spoken (low `speechiness`) and are not live (low `liveness`). 
Examining the plot again for the above four features gives us more relationships to hypothesise about. The wide range in `valence` could indicate shifts in the happiness of her songs, like her songs becoming less happy. The range of `energy` indicates that there are vast differences in the power and drive of her songs. Large differences in `danceability` could indicate that Swift is either moving away or towards more danceable tunes. 
Lastly, the difference in `acousticness` could indicate that Taylor Swift is also switching from commercial and electronic sounding songs to more acoustic songs. Moreover, scrutinising the violin plot of `acousticness` also hints at polarisation. There are two visible bulges in the plot, indicate two areas of high density. This means that Taylor's songs which have acoustic elements likely do not have any electronic elements, vice versa, indicating her preference for keeping the two type of songs separate.
These plots were great at hinting at potential large differences in musical features within Swift's repertoire, but they do not give us any information about the trends of the features. We need a way to observe the changes in the highly variant features across time.
Hence, we will be plotting `valence`, `acousticness`, `energy` and `danceability` in a line graph in the next part.


### b. How have the features we selected influenced Taylor Swift's popularity?

#### Methodology
We plan to investigate how the selected features with the most variability (from part (a)) might impact Taylor Swift’s receptivity across her career. 
By plotting these features along with a line representing her album receptivity over time, we will be able to observe patterns and potential correlations,
thus revealing how changes in certain musical characteristics might cause a shift in listener interest and popularity. Normalised Tempo is also included here to analyse its trend with respect to her receptivity.
Receptivity is read from the right y-axis while the feature values with normalised tempo are read from the left y-axis. Each album has a unique release date, allowing us to directly plot their attributes directly using the release dates. We obtain musical attribute data from `taylor_all_songs` (converted for plotting into `taylor_long`) 
and Receptivity from `taylor_album_summary`. 

#### Plot
```{r lineplot-dual-axes, fig.width=10, fig.height=4}
ggplot(taylor_long %>% filter(labels %in% c("acousticness", "valence", "energy", "danceability", "tempo")), aes(x = album_release, y = values, color = labels)) +
  geom_smooth(method = "loess",
              se = FALSE,
              formula = y ~ x,
              span = 0.8,
              size = 1.2) +
  stat_smooth(se = FALSE, geom = "area",
              method = "loess", alpha = .1,
              span = 0.8, aes(fill = labels), show.legend=F) +
  geom_line(data = taylor_album_summary,
            aes(x = as.Date(album_release), 
                y = Receptivity / 100,
                color = "Receptivity"),
            size = 2, linetype = "solid", lineend = "round") +
  scale_y_continuous(
    name = "Feature Magnitude (0 - 1)",
    sec.axis = sec_axis(~ . * 100,
                        name = "Receptivity (%)") # (Holtz, n.d.)
  ) +
  labs(title = "Musical Attributes and Receptivity Across Taylor Swift Albums",
       x = "Album Release Date", y = "Feature Values") +
  scale_color_manual(values = c("tempo" = "brown", "acousticness" = "blue", "valence" = "red", "energy" = "green", "danceability" = "purple", "Popularity" = "black"),
  labels = c("Acousticness","Danceability","Energy","Tempo","Valence")) +
  scale_fill_manual(values = c("tempo" = "brown", "acousticness" = "blue", "valence" = "red", "energy" = "green", "danceability" = "purple"), guide = "none",
  labels = c("Acousticness","Danceability","Energy","Tempo","Valence")) +
  scale_fill_colorblind() +
  theme_minimal() +
  theme(legend.position = "top",
  axis.line.y.right = element_line(colour = "Black"),
  axis.ticks.y.right = element_line(color = "red"),
  axis.ticks.length.y.right = unit(.25, "cm"),
  axis.line.y.left = element_line(color = "brown"),
  axis.ticks.y.left = element_line(color = "red"),
  axis.ticks.length.y.left = unit(.25, "cm"),
  aspect.ratio = 0.4)
```


#### Discussion

Off the bat, we observe that Receptivity has increased over the years, meaning that Taylor Swift's audience are liking her songs more. Since her fans perception of her songs are directly influenced by the features of the songs, we can ascertain that changes in those features are most likely the reason for the increase in receptivity.
We also notice that Valence and Energy are decreasing. This means that her songs are becoming sadder and less bold; more withdrawn and moody. Danceability has been on an upward trend, indicating greater emphasis on punch, rhythm and vibe in her songs. Tempo has also been decreasing, indicating slower songs.
Acousticness seems to have the most interesting trend. Acousticness was low and decreasing from mid 2010s to 2015, before sharply increasing between 2015 and after 2020. 2015 to after 2020 is also the period when Taylor Swift's receptivity increased significantly, indicating that her audience responded positively to her change in musical style.
Overall, there seems to be a noted shift towards rhythmic and punchy songs that are sad and acoustically driven. We think that her audience received this shift well because they were yearning for something different from the usual mainstream pop soundscape of the early 2000s and mid 2010s which is characterized by Electronic Dance music and piercing Disco pop sounds (Savage, 2020).

### c. Which feature(s) has/have the greatest impact on Taylor Swift's songs?

#### Methodology
Lastly, we will be zooming into Swift's most highly rated album to investigate this subquestion. Here, we will examine how each feature contributes proportionally to her songs. 
This stacked bar chart illustrates each song’s feature makeup within the album, revealing which musical elements are dominant in her songs and may have potentially driven their success. 
This analysis complements the previous sections by showing the relative importance of each feature in her highest-rated album. You may refer to the table below the plot to check which songs correspond to the track numbers in the plot.

*Disclaimer: Track Numbers reflected in the table and plot do not correspond to the official track numbers. They have been mapped to the track names according to the order seen in the plot for ease of reading.*

#### Plot
```{r proportion-plot-ALTERNATIVE}
# Finding her most popular album
most_popular_album <- taylor_album_summary %>%
  arrange(desc(Receptivity)) %>%
  head(1) %>%
  pull(album_name)

# Filtering the songs from her most popular album
most_popular_album_songs <- taylor_all_songs %>%
  filter(album_name == most_popular_album) %>%
  select(album_name, track_number, track_name, danceability, acousticness, energy, valence)
# Reshape the data into long format for plotting
scaled_songs_long <- most_popular_album_songs %>%
  pivot_longer(cols = danceability:valence, 
               names_to = "feature", 
               values_to = "value") %>%
  group_by(track_name) %>%
  mutate(total_value = sum(value)) %>%
  ungroup()

# Check the mean value of each feature
feature_mean <- scaled_songs_long %>%
  select(feature, total_value) %>%
  group_by(feature) %>%
  summarize(mean = mean(total_value)) %>%
  arrange(mean) %>%
  pull(feature)

scaled_songs_long <- scaled_songs_long %>%
  arrange(total_value) %>%
  pivot_wider(names_from = "feature", values_from = "value") %>%
  arrange(desc(total_value)) %>%
  mutate(new_track_number = row_number()) %>%
  pivot_longer(cols = danceability:valence, names_to = "feature", values_to = "value")

# Plot with sorted order
ggplot(scaled_songs_long, aes(x = value, y = as.factor(new_track_number), fill = feature)) +
  geom_bar(stat = "identity", position = "stack") +
  theme_minimal() +
  labs(title = paste("Composition of Significant Features of each Song in the \nHighest Rated Album:", most_popular_album),
       x = "Total Magnitude of Features", y = "Songs (Track Number)",
       fill = "Feature", subtitle = "Sorted by Total Score") +
  theme(
    axis.text.y.left = element_text(size = 9),
    panel.grid.major.x = element_line(color = "#addced"),
    plot.title = element_text(size = 12, vjust = 2, face = "bold"),
    plot.subtitle = element_text(size = 8, face = 3),
    aspect.ratio = 0.8,
    axis.title.y.left = element_text(vjust = 2, size = 11)
  ) +
  scale_fill_viridis_d(labels = c("Acousticness","Danceability","Energy","Valence")) +
  coord_flip()

# Display song names mapped to track numbers
album_songs_table <- scaled_songs_long %>% select(c("track_name", "new_track_number")) %>% unique()
songname_tracknumber_table <- cbind(album_songs_table$new_track_number, album_songs_table$track_name)
kable(songname_tracknumber_table, 
      col.names = c("Track Number", "Album Songs"), 
      caption = paste("Songs within", most_popular_album, "mapped to Track Number"))
```

#### Discussion
The stacked bar chart for Swift's highest rated album reveals the distribution of key musical features (i.e. `danceability`, `acousticness`, `energy`, and `valence`) across each track, sorted by total feature magnitudes. By arranging the songs in descending order of their overall feature composition, we get an intuitive sense of the relative importance and magnitude of each feature for individual songs in this album.
Our visualisation shows a clear variability in how features contribute to individual songs. Songs with high total feature values tend to have substantial contributions from `danceability`, `energy` and `valence`, highlighting how upbeat tracks may play a significant role in the album's receptivity. `Acousticness`, though generally lower across tracks, appears sporadically higher in a few songs, suggesting moments where a more subdued, acoustic quality might contrast the otherwise energetic and dynamic nature of the album.
From these insights, it becomes evident that Swift’s most succesful album combines a balance of high-energy elements with a degree of emotional resonance (`valence`), which could contribute significantly to listener engagement and receptivity. Acoustic elements, while less dominant, add texture to specific tracks, possibly creating memorable contrast and supporting the overall album narrative.
This analysis indicates that `danceability`, `energy` and `valence` are the more dominant, high-variability features likely driving the album's success, while `acousticness` provide complementary qualities. Understanding this mix could provide insights into audience preferences and help pinpoint stylistic choices that resonate widely, explaining both the commercial and emotional impact of Swift's popular tracks. 

The critical acclaim of this album also likely means that Taylor Swift will be creating more songs in the future following the same musical pallate. We can hope to see more acoustic songs released alongside commercial tracks to satiate the hunger of her fans. However, music has an ever changing facade. What was popular last year could be boring this year, hence to predict trends in music is a little whimsical. Our analysis of the dataset also highlights this quality of music in how musical features are highly varied across songs and
trends can sometimes alarmingly change course, like how `acousticness` suddenly spiked in 2015 for Taylor Swift's songs. However, it is still worth it to study what makes great songs, great.


## 5. Teamwork



## 6. References
Harmon, J. (2023, October 16). Taylor Swift. GitHub. https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-10-17/readme.md    
Holtz, Y. (n.d.). Dual Y axis with R and ggplot2. The R Graph Gallery – Help and inspiration for R charts. https://r-graph-gallery.com/line-chart-dual-Y-axis-ggplot2.html  
Metacritic. (2023). How do you compute METASCORES? Retrieved November 7, 2024, from https://metacritichelp.zendesk.com/hc/en-us/articles/14478499933079-How-do-you-compute-METASCORES  
Metacritic. (n.d.). Taylor Swift by Taylor Swift. https://www.metacritic.com/music/taylor-swift/taylor-swift/user-reviews  
Savage, M. (2020, January 11). Five ways music changed in the 2010s. BBC. https://www.bbc.com/news/entertainment-arts-51061099
